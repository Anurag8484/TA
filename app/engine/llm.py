import os
import requests
from dotenv import load_dotenv

load_dotenv(dotenv_path=".env", override=True)  # Load .env with priority

AIPROXY_URL = "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions"
AIPROXY_TOKEN = os.getenv("OPENAI_API_KEY")  # Note: this is still for AI Proxy


def ask_llm(system_prompt: str, user_prompt: str) -> str:
    if not AIPROXY_TOKEN:
        raise EnvironmentError("‚ùå Missing OPENAI_API_KEY in .env")

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {AIPROXY_TOKEN}"
    }

    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    }

    response = requests.post(AIPROXY_URL, headers=headers, json=payload)

    try:
        response.raise_for_status()
        data = response.json()

        # ‚úÖ Minimal but useful feedback
        content = data["choices"][0]["message"]["content"]
        cost = data.get("cost")
        if cost is not None:
            print(f"‚úÖ LLM responded successfully. üí∞ Cost: ${cost:.6f}")
        else:
            print("‚úÖ LLM responded successfully.")

        return content

    except requests.exceptions.HTTPError as e:
        print("‚ùå HTTP Error:", e)
        print("üîç Response content:", response.text)
        raise
    except KeyError as e:
        print("‚ùå Unexpected response structure. Missing key:", e)
        print("üîç Full response:", response.json())
        raise

# import os
# import requests

# from dotenv import load_dotenv
# load_dotenv(dotenv_path=".env", override=True)  # Force reload


# AIPROXY_URL = "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions"
# AIPROXY_TOKEN = os.getenv("OPENAI_API_KEY")


# def ask_llm(system_prompt: str, user_prompt: str) -> str:
#     if not AIPROXY_TOKEN:
#         raise EnvironmentError("‚ùå Missing AIPROXY_TOKEN in .env")

#     headers = {
#         "Content-Type": "application/json",
#         "Authorization": f"Bearer {AIPROXY_TOKEN}"
#     }

#     payload = {
#         "model": "gpt-4o-mini",
#         "messages": [
#             {"role": "system", "content": system_prompt},
#             {"role": "user", "content": user_prompt}
#         ]
#     }

#     print("üì§ Sending to AI Proxy:", payload)

#     response = requests.post(AIPROXY_URL, headers=headers, json=payload)

#     try:
#         response.raise_for_status()
#         data = response.json()
#         print("‚úÖ LLM raw response:", data)
#         print("‚úÖ AIPROXY_TOKEN found:", bool(AIPROXY_TOKEN))
#         return data["choices"][0]["message"]["content"]
#     except Exception as e:
#         print("‚ùå LLM Error:", e)
#         print("‚ùå Full response text:", response.text)
#         raise
